{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **jaeeadjuster**\n",
        "This is a forced alignment tool for adjusting duration of words between Native speaker's English & Japanese-accented English.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZMdK_6xXYTUm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6IydpCEEYLq",
        "outputId": "2727ddc9-09e2-4df1-9cf6-c2ad86a84ea3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Collecting git+https://github.com/jianfch/stable-ts.git\n",
            "  Cloning https://github.com/jianfch/stable-ts.git to /tmp/pip-req-build-89snmm7v\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/jianfch/stable-ts.git /tmp/pip-req-build-89snmm7v\n",
            "  Resolved https://github.com/jianfch/stable-ts.git to commit 91cf2b15085ea0b826fb00c517f2132b66cbb651\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stable-ts==2.10.1) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from stable-ts==2.10.1) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from stable-ts==2.10.1) (2.0.2+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-ts==2.10.1) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from stable-ts==2.10.1) (10.1.0)\n",
            "Requirement already satisfied: transformers>=4.19.0 in /usr/local/lib/python3.10/dist-packages (from stable-ts==2.10.1) (4.33.1)\n",
            "Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.10/dist-packages (from stable-ts==2.10.1) (0.2.0)\n",
            "Requirement already satisfied: openai-whisper==20230314 in /usr/local/lib/python3.10/dist-packages (from stable-ts==2.10.1) (20230314)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python==0.2.0->stable-ts==2.10.1) (0.18.3)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314->stable-ts==2.10.1) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314->stable-ts==2.10.1) (0.56.4)\n",
            "Requirement already satisfied: tiktoken==0.3.1 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314->stable-ts==2.10.1) (0.3.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.1->openai-whisper==20230314->stable-ts==2.10.1) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.1->openai-whisper==20230314->stable-ts==2.10.1) (2.31.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314->stable-ts==2.10.1) (3.27.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314->stable-ts==2.10.1) (3.12.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314->stable-ts==2.10.1) (16.0.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->stable-ts==2.10.1) (0.17.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->stable-ts==2.10.1) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->stable-ts==2.10.1) (6.0.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->stable-ts==2.10.1) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->stable-ts==2.10.1) (0.3.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->stable-ts==2.10.1) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->stable-ts==2.10.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->stable-ts==2.10.1) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->stable-ts==2.10.1) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers>=4.19.0->stable-ts==2.10.1) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314->stable-ts==2.10.1) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314->stable-ts==2.10.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314->stable-ts==2.10.1) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314->stable-ts==2.10.1) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->stable-ts==2.10.1) (2.1.3)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230314->stable-ts==2.10.1) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230314->stable-ts==2.10.1) (67.7.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->stable-ts==2.10.1) (1.3.0)\n",
            "Requirement already satisfied: alkana in /usr/local/lib/python3.10/dist-packages (0.0.3)\n",
            "Requirement already satisfied: jaconv in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.7.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.6)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.5)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (67.7.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (23.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.7.22)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: pyrubberband in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pyrubberband) (1.16.0)\n",
            "Requirement already satisfied: pysoundfile>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from pyrubberband) (0.9.0.post1)\n",
            "Requirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.10/dist-packages (from pysoundfile>=0.8.0->pyrubberband) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=0.6->pysoundfile>=0.8.0->pyrubberband) (2.21)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement stable_whisper (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for stable_whisper\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: romajitable in /usr/local/lib/python3.10/dist-packages (0.0.1)\n",
            "Requirement already satisfied: PySegmentKit in /usr/local/lib/python3.10/dist-packages (0.2.1)\n"
          ]
        }
      ],
      "source": [
        "#import libraries\n",
        "!pip install -U git+https://github.com/jianfch/stable-ts.git\n",
        "!pip install alkana\n",
        "!pip install jaconv\n",
        "!pip install librosa\n",
        "!pip install pydub\n",
        "!pip install pyrubberband\n",
        "!pip install stable_whisper\n",
        "!pip install romajitable\n",
        "!pip install PySegmentKit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install -y rubberband-cli"
      ],
      "metadata": {
        "id": "JveLlR8AyG75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75e6d5d2-4233-470f-c45a-9e57ba40fa94"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.83)] [Connecting to security.ub\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (185.125.190.36)] [Connecting to ppa.laun\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.36)] [\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (185.125.190.36)] [Connecting to ppa.laun\r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "rubberband-cli is already the newest version (2.0.0-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 23 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hiragana to phonemes of Julius with delimiters\n",
        "def conv2julius_divide(s):\n",
        "    s = s.replace('う゛ぁ',' b a/')\n",
        "    s = s.replace('う゛ぃ',' b i/')\n",
        "    s = s.replace('う゛ぇ',' b e/')\n",
        "    s = s.replace('う゛ぉ',' b o/')\n",
        "    s = s.replace('う゛ゅ',' by u/')\n",
        "\n",
        "    s = s.replace('あぁ',' a a/')\n",
        "    s = s.replace('いぃ',' i i/')\n",
        "    s = s.replace('いぇ',' i e/')\n",
        "    s = s.replace('いゃ',' y a/')\n",
        "    s = s.replace('うぅ',' u:/')\n",
        "    s = s.replace('えぇ',' e e/')\n",
        "    s = s.replace('おぉ',' o:/')\n",
        "    s = s.replace('かぁ',' k a:/')\n",
        "    s = s.replace('きぃ',' k i:/')\n",
        "    s = s.replace('くぅ',' k u:/')\n",
        "    s = s.replace('くゃ',' ky a/')\n",
        "    s = s.replace('くゅ',' ky u/')\n",
        "    s = s.replace('くょ',' ky o/')\n",
        "    s = s.replace('けぇ',' k e:/')\n",
        "    s = s.replace('こぉ',' k o:/')\n",
        "    s = s.replace('がぁ',' g a:/')\n",
        "    s = s.replace('ぎぃ',' g i:/')\n",
        "    s = s.replace('ぐぅ',' g u:/')\n",
        "    s = s.replace('ぐゃ',' gy a/')\n",
        "    s = s.replace('ぐゅ',' gy u/')\n",
        "    s = s.replace('ぐょ',' gy o/')\n",
        "    s = s.replace('げぇ',' g e:/')\n",
        "    s = s.replace('ごぉ',' g o:/')\n",
        "    s = s.replace('さぁ',' s a:/')\n",
        "    s = s.replace('しぃ',' sh i:/')\n",
        "    s = s.replace('すぅ',' s u:/')\n",
        "    s = s.replace('すゃ',' sh a/')\n",
        "    s = s.replace('すゅ',' sh u/')\n",
        "    s = s.replace('すょ',' sh o/')\n",
        "    s = s.replace('せぇ',' s e:/')\n",
        "    s = s.replace('そぉ',' s o:/')\n",
        "    s = s.replace('ざぁ',' z a:/')\n",
        "    s = s.replace('じぃ',' j i:/')\n",
        "    s = s.replace('ずぅ',' z u:/')\n",
        "    s = s.replace('ずゃ',' zy a/')\n",
        "    s = s.replace('ずゅ',' zy u/')\n",
        "    s = s.replace('ずょ',' zy o/')\n",
        "    s = s.replace('ぜぇ',' z e:/')\n",
        "    s = s.replace('ぞぉ',' z o:/')\n",
        "    s = s.replace('たぁ',' t a:/')\n",
        "    s = s.replace('ちぃ',' ch i:/')\n",
        "    s = s.replace('つぁ',' ts a/')\n",
        "    s = s.replace('つぃ',' ts i/')\n",
        "    s = s.replace('つぅ',' ts u:/')\n",
        "    s = s.replace('つゃ',' ch a/')\n",
        "    s = s.replace('つゅ',' ch u/')\n",
        "    s = s.replace('つょ',' ch o/')\n",
        "    s = s.replace('つぇ',' ts e/')\n",
        "    s = s.replace('つぉ',' ts o/')\n",
        "    s = s.replace('てぇ',' t e:/')\n",
        "    s = s.replace('とぉ',' t o:/')\n",
        "    s = s.replace('だぁ',' d a:/')\n",
        "    s = s.replace('ぢぃ',' j i:/')\n",
        "    s = s.replace('づぅ',' d u:/')\n",
        "    s = s.replace('づゃ',' zy a/')\n",
        "    s = s.replace('づゅ',' zy u/')\n",
        "    s = s.replace('づょ',' zy o/')\n",
        "    s = s.replace('でぇ',' d e:/')\n",
        "    s = s.replace('どぉ',' d o:/')\n",
        "    s = s.replace('なぁ',' n a:/')\n",
        "    s = s.replace('にぃ',' n i:/')\n",
        "    s = s.replace('ぬぅ',' n u:/')\n",
        "    s = s.replace('ぬゃ',' ny a/')\n",
        "    s = s.replace('ぬゅ',' ny u/')\n",
        "    s = s.replace('ぬょ',' ny o/')\n",
        "    s = s.replace('ねぇ',' n e:/')\n",
        "    s = s.replace('のぉ',' n o:/')\n",
        "    s = s.replace('はぁ',' h a:/')\n",
        "    s = s.replace('ひぃ',' h i:/')\n",
        "    s = s.replace('ふぅ',' f u:/')\n",
        "    s = s.replace('ふゃ',' hy a/')\n",
        "    s = s.replace('ふゅ',' hy u/')\n",
        "    s = s.replace('ふょ',' hy o/')\n",
        "    s = s.replace('へぇ',' h e:/')\n",
        "    s = s.replace('ほぉ',' h o:/')\n",
        "    s = s.replace('ばぁ',' b a:/')\n",
        "    s = s.replace('びぃ',' b i:/')\n",
        "    s = s.replace('ぶぅ',' b u:/')\n",
        "    s = s.replace('ふゃ',' hy a/')\n",
        "    s = s.replace('ぶゅ',' by u/')\n",
        "    s = s.replace('ふょ',' hy o/')\n",
        "    s = s.replace('べぇ',' b e:/')\n",
        "    s = s.replace('ぼぉ',' b o:/')\n",
        "    s = s.replace('ぱぁ',' p a:/')\n",
        "    s = s.replace('ぴぃ',' p i:/')\n",
        "    s = s.replace('ぷぅ',' p u:/')\n",
        "    s = s.replace('ぷゃ',' py a/')\n",
        "    s = s.replace('ぷゅ',' py u/')\n",
        "    s = s.replace('ぷょ',' py o/')\n",
        "    s = s.replace('ぺぇ',' p e:/')\n",
        "    s = s.replace('ぽぉ',' p o:/')\n",
        "    s = s.replace('まぁ',' m a:/')\n",
        "    s = s.replace('みぃ',' m i:/')\n",
        "    s = s.replace('むぅ',' m u:/')\n",
        "    s = s.replace('むゃ',' my a/')\n",
        "    s = s.replace('むゅ',' my u/')\n",
        "    s = s.replace('むょ',' my o/')\n",
        "    s = s.replace('めぇ',' m e:/')\n",
        "    s = s.replace('もぉ',' m o:/')\n",
        "    s = s.replace('やぁ',' y a:/')\n",
        "    s = s.replace('ゆぅ',' y u:/')\n",
        "    s = s.replace('ゆゃ',' y a:/')\n",
        "    s = s.replace('ゆゅ',' y u:/')\n",
        "    s = s.replace('ゆょ',' y o:/')\n",
        "    s = s.replace('よぉ',' y o:/')\n",
        "    s = s.replace('らぁ',' r a:/')\n",
        "    s = s.replace('りぃ',' r i:/')\n",
        "    s = s.replace('るぅ',' r u:/')\n",
        "    s = s.replace('るゃ',' ry a/')\n",
        "    s = s.replace('るゅ',' ry u/')\n",
        "    s = s.replace('るょ',' ry o/')\n",
        "    s = s.replace('れぇ',' r e:/')\n",
        "    s = s.replace('ろぉ',' r o:/')\n",
        "    s = s.replace('わぁ',' w a:/')\n",
        "    s = s.replace('をぉ',' o:/')\n",
        "\n",
        "    s = s.replace('う゛',' b u/')\n",
        "    s = s.replace('でぃ',' d i/')\n",
        "    s = s.replace('でぇ',' d e:/')\n",
        "    s = s.replace('でゃ',' dy a/')\n",
        "    s = s.replace('でゅ',' dy u/')\n",
        "    s = s.replace('でょ',' dy o/')\n",
        "    s = s.replace('てぃ',' t i/')\n",
        "    s = s.replace('てぇ',' t e:/')\n",
        "    s = s.replace('てゃ',' ty a/')\n",
        "    s = s.replace('てゅ',' ty u/')\n",
        "    s = s.replace('てょ',' ty o/')\n",
        "    s = s.replace('すぃ',' s i/')\n",
        "    s = s.replace('ずぁ',' z u a/')\n",
        "    s = s.replace('ずぃ',' z i/')\n",
        "    s = s.replace('ずぅ',' z u/')\n",
        "    s = s.replace('ずゃ',' zy a/')\n",
        "    s = s.replace('ずゅ',' zy u/')\n",
        "    s = s.replace('ずょ',' zy o/')\n",
        "    s = s.replace('ずぇ',' z e/')\n",
        "    s = s.replace('ずぉ',' z o/')\n",
        "    s = s.replace('きゃ',' ky a/')\n",
        "    s = s.replace('きゅ',' ky u/')\n",
        "    s = s.replace('きょ',' ky o/')\n",
        "    s = s.replace('しゃ',' sh a/')\n",
        "    s = s.replace('しゅ',' sh u/')\n",
        "    s = s.replace('しぇ',' sh e/')\n",
        "    s = s.replace('しょ',' sh o/')\n",
        "    s = s.replace('ちゃ',' ch a/')\n",
        "    s = s.replace('ちゅ',' ch u/')\n",
        "    s = s.replace('ちぇ',' ch e/')\n",
        "    s = s.replace('ちょ',' ch o/')\n",
        "    s = s.replace('とぅ',' t u/')\n",
        "    s = s.replace('とゃ',' ty a/')\n",
        "    s = s.replace('とゅ',' ty u/')\n",
        "    s = s.replace('とょ',' ty o/')\n",
        "    s = s.replace('どぁ',' d o a/')\n",
        "    s = s.replace('どぅ',' d u/')\n",
        "    s = s.replace('どゃ',' dy a/')\n",
        "    s = s.replace('どゅ',' dy u/')\n",
        "    s = s.replace('どょ',' dy o/')\n",
        "    s = s.replace('どぉ',' d o:/')\n",
        "    s = s.replace('にゃ',' ny a/')\n",
        "    s = s.replace('にゅ',' ny u/')\n",
        "    s = s.replace('にょ',' ny o/')\n",
        "    s = s.replace('ひゃ',' hy a/')\n",
        "    s = s.replace('ひゅ',' hy u/')\n",
        "    s = s.replace('ひょ',' hy o/')\n",
        "    s = s.replace('みゃ',' my a/')\n",
        "    s = s.replace('みゅ',' my u/')\n",
        "    s = s.replace('みょ',' my o/')\n",
        "    s = s.replace('りゃ',' ry a/')\n",
        "    s = s.replace('りゅ',' ry u/')\n",
        "    s = s.replace('りょ',' ry o/')\n",
        "    s = s.replace('ぎゃ',' gy a/')\n",
        "    s = s.replace('ぎゅ',' gy u/')\n",
        "    s = s.replace('ぎょ',' gy o/')\n",
        "    s = s.replace('ぢぇ',' j e/')\n",
        "    s = s.replace('ぢゃ',' j a/')\n",
        "    s = s.replace('ぢゅ',' j u/')\n",
        "    s = s.replace('ぢょ',' j o/')\n",
        "    s = s.replace('じぇ',' j e/')\n",
        "    s = s.replace('じゃ',' j a/')\n",
        "    s = s.replace('じゅ',' j u/')\n",
        "    s = s.replace('じょ',' j o/')\n",
        "    s = s.replace('びゃ',' by a/')\n",
        "    s = s.replace('びゅ',' by u/')\n",
        "    s = s.replace('びょ',' by o/')\n",
        "    s = s.replace('ぴゃ',' py a/')\n",
        "    s = s.replace('ぴゅ',' py u/')\n",
        "    s = s.replace('ぴょ',' py o/')\n",
        "    s = s.replace('うぁ',' u a/')\n",
        "    s = s.replace('うぃ',' w i/')\n",
        "    s = s.replace('うぇ',' w e/')\n",
        "    s = s.replace('うぉ',' w o/')\n",
        "    s = s.replace('ふぁ',' f a/')\n",
        "    s = s.replace('ふぃ',' f i/')\n",
        "    s = s.replace('ふぅ',' f u/')\n",
        "    s = s.replace('ふゃ',' hy a/')\n",
        "    s = s.replace('ふゅ',' hy u/')\n",
        "    s = s.replace('ふょ',' hy o/')\n",
        "    s = s.replace('ふぇ',' f e/')\n",
        "    s = s.replace('ふぉ',' f o/')\n",
        "\n",
        "    s = s.replace('あ',' a/')\n",
        "    s = s.replace('い',' i/')\n",
        "    s = s.replace('う',' u/')\n",
        "    s = s.replace('え',' e/')\n",
        "    s = s.replace('お',' o/')\n",
        "    s = s.replace('か',' k a/')\n",
        "    s = s.replace('き',' k i/')\n",
        "    s = s.replace('く',' k u/')\n",
        "    s = s.replace('け',' k e/')\n",
        "    s = s.replace('こ',' k o/')\n",
        "    s = s.replace('さ',' s a/')\n",
        "    s = s.replace('し',' sh i/')\n",
        "    s = s.replace('す',' s u/')\n",
        "    s = s.replace('せ',' s e/')\n",
        "    s = s.replace('そ',' s o/')\n",
        "    s = s.replace('た',' t a/')\n",
        "    s = s.replace('ち',' ch i/')\n",
        "    s = s.replace('つ',' ts u/')\n",
        "    s = s.replace('て',' t e/')\n",
        "    s = s.replace('と',' t o/')\n",
        "    s = s.replace('な',' n a/')\n",
        "    s = s.replace('に',' n i/')\n",
        "    s = s.replace('ぬ',' n u/')\n",
        "    s = s.replace('ね',' n e/')\n",
        "    s = s.replace('の',' n o/')\n",
        "    s = s.replace('は',' h a/')\n",
        "    s = s.replace('ひ',' h i/')\n",
        "    s = s.replace('ふ',' f u/')\n",
        "    s = s.replace('へ',' h e/')\n",
        "    s = s.replace('ほ',' h o/')\n",
        "    s = s.replace('ま',' m a/')\n",
        "    s = s.replace('み',' m i/')\n",
        "    s = s.replace('む',' m u/')\n",
        "    s = s.replace('め',' m e/')\n",
        "    s = s.replace('も',' m o/')\n",
        "    s = s.replace('ら',' r a/')\n",
        "    s = s.replace('り',' r i/')\n",
        "    s = s.replace('る',' r u/')\n",
        "    s = s.replace('れ',' r e/')\n",
        "    s = s.replace('ろ',' r o/')\n",
        "    s = s.replace('が',' g a/')\n",
        "    s = s.replace('ぎ',' g i/')\n",
        "    s = s.replace('ぐ',' g u/')\n",
        "    s = s.replace('げ',' g e/')\n",
        "    s = s.replace('ご',' g o/')\n",
        "    s = s.replace('ざ',' z a/')\n",
        "    s = s.replace('じ',' j i/')\n",
        "    s = s.replace('ず',' z u/')\n",
        "    s = s.replace('ぜ',' z e/')\n",
        "    s = s.replace('ぞ',' z o/')\n",
        "    s = s.replace('だ',' d a/')\n",
        "    s = s.replace('ぢ',' j i/')\n",
        "    s = s.replace('づ',' z u/')\n",
        "    s = s.replace('で',' d e/')\n",
        "    s = s.replace('ど',' d o/')\n",
        "    s = s.replace('ば',' b a/')\n",
        "    s = s.replace('び',' b i/')\n",
        "    s = s.replace('ぶ',' b u/')\n",
        "    s = s.replace('べ',' b e/')\n",
        "    s = s.replace('ぼ',' b o/')\n",
        "    s = s.replace('ぱ',' p a/')\n",
        "    s = s.replace('ぴ',' p i/')\n",
        "    s = s.replace('ぷ',' p u/')\n",
        "    s = s.replace('ぺ',' p e/')\n",
        "    s = s.replace('ぽ',' p o/')\n",
        "    s = s.replace('や',' y a/')\n",
        "    s = s.replace('ゆ',' y u/')\n",
        "    s = s.replace('よ',' y o/')\n",
        "    s = s.replace('わ',' w a/')\n",
        "    s = s.replace('を',' o/')\n",
        "    s = s.replace('ん',' N/')\n",
        "    s = s.replace('っ',' q/')\n",
        "    if ('ー' in s):\n",
        "      s = s.replace(\"/ー\",\"ー\")\n",
        "      s = s.replace('ー',':/')\n",
        "\n",
        "    s = s.replace('ぁ',' a/')\n",
        "    s = s.replace('ぃ',' i/')\n",
        "    s = s.replace('ぅ',' u/')\n",
        "    s = s.replace('ぇ',' e/')\n",
        "    s = s.replace('ぉ',' o/')\n",
        "    s = s.replace('ゎ',' w a/')\n",
        "\n",
        "    s = s[1:]\n",
        "\n",
        "    s = re.sub(r':+', ':', s)\n",
        "\n",
        "    return s"
      ],
      "metadata": {
        "id": "s5g5Qgb86NNx"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import stable_whisper\n",
        "from collections import OrderedDict\n",
        "import re\n",
        "import jaconv\n",
        "import alkana\n",
        "import librosa\n",
        "import time\n",
        "import soundfile as sf\n",
        "import shutil\n",
        "import pathlib\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "import wave\n",
        "import pyrubberband as pyrb\n",
        "from natsort import natsorted\n",
        "import romajitable\n",
        "from PySegmentKit import PySegmentKit, PSKError\n",
        "import alkana\n",
        "import re\n",
        "\n",
        "#calculating audio duration\n",
        "def get_audio_duration(file_path):\n",
        "  with wave.open(file_path,  'rb') as wr:\n",
        "    fn = wr.getnframes()\n",
        "    fr = wr.getframerate()\n",
        "    duration =  1.0 * fn / fr\n",
        "    return duration\n",
        "\n",
        "#adjusting duration of last words on julius .lab\n",
        "def adjust_max_sec(od,file_name):\n",
        "  data = od.popitem()\n",
        "  with wave.open(file_name,  'rb') as wr:\n",
        "      fr = wr.getframerate()\n",
        "      fn = wr.getnframes()\n",
        "      length = 1.0*fn/fr\n",
        "\n",
        "  od[data[0].replace(\".\",\"\")] = [data[1][0],length]\n",
        "  od.move_to_end(data[0].replace(\".\",\"\"))\n",
        "  print(od[data[0].replace(\".\",\"\")])\n",
        "\n",
        "  return od\n",
        "\n",
        "#speech recogniton using whisper & making phoneme dictionary\n",
        "def load_recognize_speech(file_name):\n",
        "  #load & recognition\n",
        "  files:list[str] = [file_name]\n",
        "  od = OrderedDict()\n",
        "  new_od = OrderedDict()\n",
        "  model = stable_whisper.load_model('base')\n",
        "  recoginzed_txt = \"\"\n",
        "  for i, file in enumerate(files):\n",
        "    print(\"## {}\".format(file))\n",
        "    result = model.transcribe(file, language= \"en\", verbose=True)\n",
        "    for word in result.all_words():\n",
        "\n",
        "      if(word.word[1:] in od):\n",
        "        od[word.word[1:]].append(word.start)\n",
        "        od[word.word[1:]].append(word.end)\n",
        "      else:\n",
        "        od[word.word[1:]] = [word.start, word.end]\n",
        "\n",
        "      recoginzed_txt = recoginzed_txt + word.word + \" \"\n",
        "\n",
        "  new_od = adjust_max_sec(od,file_name)\n",
        "\n",
        "  recoginzed_txt = recoginzed_txt[:-1]\n",
        "\n",
        "  return new_od,recoginzed_txt\n",
        "\n",
        "#converting from English to Japanese hiragana for a sentence\n",
        "def converter_en_to_jp_sen(txt):\n",
        "  txt_split = txt[:-1].split(\" \")\n",
        "  txt_split = list(filter(lambda x: x != \"\", txt_split))\n",
        "  katakana_txt_list = []\n",
        "  for i in txt_split:\n",
        "    if(alkana.get_kana(i) is None):#if there are no information in the dictionary, use rulebase\n",
        "      katakana_txt_list.append(romajitable.to_kana(i).katakana)\n",
        "    else:\n",
        "      katakana_txt_list.append(alkana.get_kana(i))\n",
        "\n",
        "  katakana_txt = \" \".join(katakana_txt_list)\n",
        "  kana_txt =  jaconv.kata2hira(katakana_txt)\n",
        "  kana_txt = kana_txt.replace(\"ゔ\",\"う゛\")\n",
        "  katakana_pho = jaconv.hiragana2julius(kana_txt)\n",
        "\n",
        "  return katakana_pho,kana_txt.replace(\" \",\"\")\n",
        "\n",
        "#converting from English to Japanese hiragana for a word\n",
        "def converter_en_to_jp_word(word):\n",
        "  if(alkana.get_kana(word) is None):\n",
        "    word =  romajitable.to_kana(word)\n",
        "    word = word.katakana\n",
        "  else:\n",
        "    word = alkana.get_kana(word)\n",
        "\n",
        "  word =  jaconv.kata2hira(word)\n",
        "  word = word.replace(\"ゔ\",\"う゛\")\n",
        "  word = conv2julius_divide(word)\n",
        "\n",
        "  return word\n",
        "\n",
        "#resampling for audio\n",
        "def resample_wav(input_path, output_path, target_sr=16000):\n",
        "    y, sr = librosa.load(input_path, sr=None)\n",
        "    y_resampled = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
        "    sf.write(output_path, y_resampled, target_sr, subtype=\"PCM_16\")\n",
        "\n",
        "#making dictionary from results of Julius\n",
        "def julius_analysis(lab_path):\n",
        "  data_dict = {}\n",
        "  with open(lab_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            print(file)\n",
        "            for line in file:\n",
        "              start_time, end_time, phone = line.strip().split(' ')\n",
        "              if(phone in data_dict):\n",
        "                data_dict[phone] += [start_time,end_time]\n",
        "              else:\n",
        "                data_dict[phone] = [start_time,end_time]\n",
        "  return data_dict\n",
        "\n",
        "#conducting phoneme segmentation using Julius\n",
        "def julius(dir):\n",
        "  sk = PySegmentKit(dir,\n",
        "    disable_silence_at_ends=False,\n",
        "    leave_dict=False,\n",
        "    debug=False,\n",
        "    triphone=False,\n",
        "    input_mfcc=False)\n",
        "\n",
        "  try:\n",
        "      segmented = sk.segment()\n",
        "      for result in segmented.keys():\n",
        "          print(\"=====Segmentation result of {}.wav=====\".format(result))\n",
        "          for begintime, endtime, unit in segmented[result]:\n",
        "              print(\"{:.7f} {:.7f} {}\".format(begintime, endtime, unit))\n",
        "  except PSKError as e:\n",
        "      print(e)\n",
        "\n",
        "#Making dictionary from Japanese phoneme & English phoneme\n",
        "def make_duration_jp(od_speech_a,od_speech_b):\n",
        "  time_list = []\n",
        "  new_od_speech_b = OrderedDict()\n",
        "  for i in od_speech_a.keys():\n",
        "    search_sentence_list = i.split(\"/\")\n",
        "    for phone in search_sentence_list:\n",
        "      search_phone_list = phone.split(\" \")\n",
        "      search_phone_list = list(filter(lambda x: x != \"\", search_phone_list))\n",
        "\n",
        "      for j in search_phone_list:\n",
        "        time_list += [float(od_speech_b[j][0]),float(od_speech_b[j][1])]\n",
        "        del od_speech_b[j][0:2]\n",
        "\n",
        "      min_data = min(time_list)\n",
        "      max_data = max(time_list)\n",
        "\n",
        "    new_od_speech_b[i] = [min_data,max_data]\n",
        "    time_list.clear()\n",
        "\n",
        "  first_key = next(iter(new_od_speech_b))\n",
        "  new_od_speech_b[first_key] = [float(od_speech_b[\"silB\"][0]),new_od_speech_b[first_key][1]]\n",
        "  last_key = next(reversed(new_od_speech_b))\n",
        "  new_od_speech_b[last_key] = [new_od_speech_b[last_key][0],float(od_speech_b[\"silE\"][1])]\n",
        "  return new_od_speech_b\n",
        "\n",
        "#Making audio files for each word\n",
        "def split_wav_usedict(input_file, output_folder, dict):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "    num = 0\n",
        "    for i in dict:\n",
        "      sourceAudio = AudioSegment.from_wav(input_file)\n",
        "      processedAudio =  sourceAudio[dict[i][0]*1000:dict[i][1]*1000]\n",
        "      processedAudio.export(output_folder + \"/\"+str(num)+\".wav\", format=\"wav\")\n",
        "      num += 1\n",
        "\n",
        "\n",
        "#Adjusting Japanese speech using English duration\n",
        "def align_speech(file_b,od_speech_a,od_speech_b):#発話区間調整関数\n",
        "  field_put_folder = \"/content/field\"\n",
        "  out_put_folder = \"/content/output\"\n",
        "\n",
        "  if not os.path.exists(out_put_folder):\n",
        "    os.makedirs(out_put_folder)\n",
        "\n",
        "  split_wav_usedict(file_b,field_put_folder,od_speech_b)\n",
        "  count = 0\n",
        "\n",
        "  for i in od_speech_b.keys():\n",
        "    file_path_a = field_put_folder + \"/\" + str(count) + \".wav\"\n",
        "    data_one = od_speech_a[i][1]\n",
        "    data_zero = od_speech_a[i][0]\n",
        "    target_duration_a =  data_one - data_zero\n",
        "    source_duration = get_audio_duration(file_path_a)\n",
        "    multi_num = source_duration/target_duration_a\n",
        "    y, sr   = librosa.load(file_path_a, sr=16000, mono=True)\n",
        "    y_fast = pyrb.time_stretch(y, sr, multi_num)\n",
        "    sf.write(file_path_a,y_fast,sr)\n",
        "\n",
        "    count += 1\n",
        "\n",
        "  for k in range(count):\n",
        "    if(k == 0):\n",
        "      audio = AudioSegment.from_wav( field_put_folder + \"/\" + str(k) + \".wav\")\n",
        "    else:\n",
        "      audio+=AudioSegment.from_wav( field_put_folder + \"/\" + str(k) + \".wav\")\n",
        "\n",
        "  shutil.rmtree( field_put_folder)\n",
        "  os.mkdir( field_put_folder)\n",
        "\n",
        "  audio.export(out_put_folder + \"/\" + str(file_b).split(\"/\")[-1], format=\"wav\")\n",
        "\n",
        "#Making a directory concisted of audio & text\n",
        "def make_dir(audio_path,txt_path):\n",
        "    output_directory = \"/content/path_to_output_directory\"\n",
        "    os.makedirs(output_directory, exist_ok=True)\n",
        "    shutil.copy(audio_path, os.path.join(output_directory, \"tem.wav\"))\n",
        "    shutil.copy(txt_path, os.path.join(output_directory, \"tem.txt\"))\n",
        "\n",
        "    return output_directory"
      ],
      "metadata": {
        "id": "xKLyNjpySQHp"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#main\n",
        "def main():\n",
        "    folder_path_us = \"/content/us\"\n",
        "    folder_path_ja = \"/content/ja\"\n",
        "    tem_path_txt_file = \"/content/tem.txt\"\n",
        "    for filename_a in natsorted(os.listdir(folder_path_us)):\n",
        "        file_path_us = os.path.join(folder_path_us, filename_a)\n",
        "        file_path_ja = os.path.join(folder_path_ja, filename_a)\n",
        "\n",
        "        model = stable_whisper.load_model('base')\n",
        "\n",
        "        od_speech_us = OrderedDict()\n",
        "        od_speech_us,recognized_text_a = load_recognize_speech(file_path_us)\n",
        "\n",
        "        new_od_speech_us = OrderedDict()\n",
        "        for i in od_speech_us.keys():\n",
        "            new_key = converter_en_to_jp_word(i)\n",
        "            new_od_speech_us[new_key] = od_speech_us[i]\n",
        "\n",
        "\n",
        "\n",
        "        japanaized_phone,kana_txt = converter_en_to_jp_sen(recognized_text_a)\n",
        "\n",
        "        f = open(tem_path_txt_file, 'w')\n",
        "        f.write(kana_txt)\n",
        "        f.close()\n",
        "\n",
        "        resample_wav(file_path_ja, file_path_ja, target_sr=16000)\n",
        "        output = make_dir(file_path_ja, tem_path_txt_file)\n",
        "        julius(output)\n",
        "        od_speech_ja = julius_analysis(output + \"/tem.lab\")\n",
        "        shutil.rmtree(output)\n",
        "\n",
        "        new_od_speech_ja = make_duration_jp(new_od_speech_us,od_speech_ja)\n",
        "\n",
        "        align_speech(file_path_ja,new_od_speech_us,new_od_speech_ja)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU0hXXz2GvFu",
        "outputId": "5315eaff-8563-4d08-f504-218cdfbe74b9"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## /content/us/H1_Harvard_Sentences_0.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_whisper/whisper_word_level.py:257: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:01.980]  A large size in stockings is hard to sell.\n",
            "-[00:00.000] -> [00:00.140] \" A\"\n",
            "-[00:00.140] -> [00:00.420] \" large\"\n",
            "-[00:00.420] -> [00:00.760] \" size\"\n",
            "-[00:00.760] -> [00:00.960] \" in\"\n",
            "-[00:00.960] -> [00:01.480] \" stockings\"\n",
            "-[00:01.480] -> [00:01.580] \" is\"\n",
            "-[00:01.580] -> [00:01.760] \" hard\"\n",
            "-[00:01.760] -> [00:01.860] \" to\"\n",
            "-[00:01.860] -> [00:01.980] \" sell.\"\n",
            "\n",
            "[1.86, 2.376]\n",
            "/content/path_to_output_directory/tem.wav\n",
            "Result saved in \"/content/path_to_output_directory/tem.lab\".\n",
            "\n",
            "=====Segmentation result of /content/path_to_output_directory/tem.wav=====\n",
            "0.0000000 0.1425000 silB\n",
            "0.1425000 0.2825000 a\n",
            "0.2825000 0.3125000 r\n",
            "0.3125000 0.5725000 a:\n",
            "0.5725000 0.7125000 j\n",
            "0.7125000 0.7525000 i\n",
            "0.7525000 0.8725000 s\n",
            "0.8725000 0.9825000 a\n",
            "0.9825000 1.0225000 i\n",
            "1.0225000 1.1225000 z\n",
            "1.1225000 1.1825000 u\n",
            "1.1825000 1.3125000 i\n",
            "1.3125000 1.3825000 N\n",
            "1.3825000 1.5125000 s\n",
            "1.5125000 1.5425000 u\n",
            "1.5425000 1.6025000 t\n",
            "1.6025000 1.6625000 o\n",
            "1.6625000 1.7525000 q\n",
            "1.7525000 1.8225000 k\n",
            "1.8225000 1.9025000 i\n",
            "1.9025000 1.9725000 N\n",
            "1.9725000 2.0025000 g\n",
            "2.0025000 2.0625000 u\n",
            "2.0625000 2.2725000 s\n",
            "2.2725000 2.3325000 u\n",
            "2.3325000 2.4125000 i\n",
            "2.4125000 2.5325000 z\n",
            "2.5325000 2.6025000 u\n",
            "2.6025000 2.7625000 h\n",
            "2.7625000 2.9125000 a:\n",
            "2.9125000 2.9925000 d\n",
            "2.9925000 3.1025000 o\n",
            "3.1025000 3.2025000 t\n",
            "3.2025000 3.3125000 u:\n",
            "3.3125000 3.4625000 s\n",
            "3.4625000 3.5225000 e\n",
            "3.5225000 3.5625000 r\n",
            "3.5625000 3.6525000 u\n",
            "3.6525000 3.7025000 silE\n",
            "<_io.TextIOWrapper name='/content/path_to_output_directory/tem.lab' mode='r' encoding='utf-8'>\n"
          ]
        }
      ]
    }
  ]
}